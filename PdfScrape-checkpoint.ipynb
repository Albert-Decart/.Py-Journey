{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfplumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4e087c3cdab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfplumber'"
     ]
    }
   ],
   "source": [
    "import pdfplumber, re,  sys, time, pandas, json, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "Header_Data0={\"Workfile\":\"\",\"PublishedDate\":\"\",\"PublishedYear\":\"\",\"Client\":\"\",\"MarketArea\":\"\"}\n",
    "Asset_Data0={\"AssetTitle\":\"\",\"SerialNumber\":\"\",\"FMV_Low\":\"\",\"FMV_High\":\"\",\"OLV_Low\":\"\",\"OLV_High\":\"\"}\n",
    "Asset_Specs0={\"Kms\":\"\",\"Hours\":\"\",\"Miles\":\"\",\"Engine\":\"\",\"EnginePower\":\"\",\"Transmission\":\"\",\"AxlesNo\":\"\",\n",
    "              \"GVWR\":\"\",\"RearAxle\":\"\",\"FrontAxle\":\"\",\"Sleeper\":\"\",\"MooseBumper\":\"\"}\n",
    "Asset_Dscp0={\"Mechanical\":\"\",\"Exterior\":\"\",\"Interior\":\"\",\"Type\":\"\",\"Condition\":\"\"}\n",
    "Market_Rsrch0={\"Ad1\":\"\",\"Ad2\":\"\",\"Ad3\":\"\",\"Ad4\":\"\",\"Auction1\":\"\",\"Auction2\":\"\",\"Auction3\":\"\",\"Dealer1\":\"\",\"Dealer2\":\"\",\"Dealer3\":\"\"}\n",
    "Other_Specs0={}\n",
    "for spec in range(1,40):\n",
    "        Other_Specs0['Spec'+str(spec)] =\"\"\n",
    "        \n",
    "JsonKeys={**Header_Data0,**Asset_Data0,**Asset_Specs0,**Asset_Dscp0,**Market_Rsrch0,**Other_Specs0}\n",
    "\n",
    "\n",
    "header_data={}\n",
    "asset_data={}\n",
    "asset_specs={}\n",
    "json_data = {}\n",
    "market_research={}\n",
    "other_specs={}\n",
    "asset_dscp={}\n",
    "\n",
    "header_data.update(Header_Data0)\n",
    "asset_data.update(Asset_Data0)\n",
    "asset_specs.update(Asset_Specs0)\n",
    "json_data = JsonKeys\n",
    "market_research.update(Market_Rsrch0)\n",
    "other_specs.update(Other_Specs0)\n",
    "asset_dscp.update(Asset_Dscp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "def readfiles():\n",
    "    pdfs = []\n",
    "    for file in glob.glob(\"*.pdf\"):\n",
    "        pdfs.append(file)\n",
    "    print(pdfs)\n",
    "    return pdfs\n",
    "\n",
    "\n",
    "# Preprocesses the raw text by removing all new lines and returning a dict (seperated by what was a newline)\n",
    "def preprocess_data(raw_text):\n",
    "    return [el.strip() for el in raw_text.splitlines() if el.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# Get data that is always in the same spot.\n",
    "def get_headerData(raw_text, header_data = {}):\n",
    "    Worked=1\n",
    "    try:\n",
    "        workfile = re.search(r'(\\w{5}\\d{10})',raw_text).group(1).strip()\n",
    "        header_data['Workfile'] = workfile\n",
    "        #processed_text = preprocess_data(raw_text)\n",
    "        # Data that is always in the same spot\n",
    "    except:\n",
    "        Worked=0\n",
    "        return Worked\n",
    "        print(\"Workfile Name ERROR\")\n",
    "    if Worked==1:\n",
    "        try:\n",
    "            header_data['PublishedDate']=re.search(r'Publication Date:\\s*(.{1,})\\n',raw_text).group(1).strip()\n",
    "            header_data['PublishedYear']=re.search(r'Publication Date:\\s*(\\w{3,12}\\s+\\d{1,2}\\W\\s)(\\d{4})\\n',raw_text).group(2).strip()\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                header_data['PublishedDate'] = re.search(r'(\\w{3,12}\\s+\\d{1,2}\\W\\s\\d{4})',raw_text).group(1).strip()\n",
    "                header_data['PublishedYear'] = re.search(r'(\\w{3,12}\\s+\\d{1,2}\\W\\s)(\\d{4})',raw_text).group(2).strip()\n",
    "\n",
    "            except:\n",
    "                print(\"header_data['Published Date']-- ERROR\")\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            header_data['Client'] = re.search(r'(Attention)(\\s{1,})(\\w{1,}\\s{1,}\\w{1,})',raw_text).group(3).strip()\n",
    "\n",
    "        except:\n",
    "            print(\"header_data['Client']-- ERROR\")\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            header_data['MarketArea'] = re.search(r'(Market Area\\s{1,}:\\s{1,})(.{1,})(\\s{1})',raw_text).group(2).strip()\n",
    "\n",
    "        except:\n",
    "            print(\"header_data['MarketArea']-- ERROR\")\n",
    "            pass\n",
    "        return Worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "def get_assetData(raw_text, asset_data):\n",
    "    KK2=1\n",
    "    Nline_raw_text=re.sub(\"\\n\",\" \",raw_text)\n",
    "    Nline_raw_text=re.sub(\"  \",\" \",Nline_raw_text)\n",
    "    Nline_raw_text=re.sub(\"  \",\" \",Nline_raw_text)\n",
    "    Nline_raw_text=re.sub(\"  \",\" \",Nline_raw_text)\n",
    "    \n",
    "    try:\n",
    "        asset_data['AssetTitle'] = re.search(r'described (.{1,}) based on',Nline_raw_text).group(1).strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            asset_data['AssetTitle'] = re.search(r'(Item\\s{1,}:\\s{1,})(\\d{4}?.{1,})(Serial Number)',Nline_raw_text).group(2).strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "        asset_data['SerialNumber'] = re.search(r'(Serial Number\\s{1,}:\\s*)(.{6,17})',Nline_raw_text).group(2).strip()\n",
    "    except :\n",
    "        asset_data['SerialNumber'] = re.search(r'(VIN\\s*)(.{17})',Nline_raw_text).group(2).strip()\n",
    "        pass\n",
    "    \n",
    "    try:# FMV/ACV FMV high low/single\n",
    "        asset_data['FMV_Low'] = re.search(r'((Fair Market Value|(Actual Cash Value)) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(5).strip()\n",
    "        asset_data['FMV_High'] = re.search(r'((Fair Market Value|(Actual Cash Value)) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))(\\s*-\\s*\\$*)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(9).strip()\n",
    "    except :\n",
    "        try:\n",
    "            asset_data['FMV_Low'] = re.search(r'((Fair Market Value|(Actual Cash Value)) (?:\\(removed\\)) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(5).strip()\n",
    "            asset_data['FMV_High'] = re.search(r'((Fair Market Value|(Actual Cash Value)) (?:\\(removed\\)) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))(\\s*-\\s*\\$*)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(9).strip()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    try:# OLV/Auction value low/single\n",
    "        asset_data['OLV_Low'] = re.search(r'(auction\\s*\\w* (of|in the)\\s{1,}\\$)(\\d{1,}(\\,\\d{2,})?)((\\s*.{1}\\s*\\$*)(\\d{1,}(\\,\\d{2,})?))',Nline_raw_text).group(3).strip()\n",
    "        asset_data['OLV_High'] = re.search(r'(auction\\s*\\w* (of|in the)\\s{1,}\\$)(\\d{1,}(\\,\\d{2,})?)((\\s*.{1}\\s*\\$*)(\\d{1,}(\\,\\d{2,})?))',Nline_raw_text).group(7).strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            asset_data['OLV_Low'] = re.search(r'((Orderly Liquidation Value) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(4).strip()\n",
    "            asset_data['OLV_High'] = re.search(r'((Orderly Liquidation Value) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))(\\s*-\\s*\\$*)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(8).strip()\n",
    "        except:\n",
    "            try:\n",
    "                asset_data['OLV_Low'] = re.search(r'((Orderly and Forced Liquidation Value) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(4).strip()\n",
    "                asset_data['OLV_High'] = re.search(r'((Orderly and Forced Liquidation Value) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))(\\s*-\\s*\\$*)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(8).strip()\n",
    "            except:\n",
    "\n",
    "                pass\n",
    "\n",
    "    if len(re.findall(r'and',asset_data['AssetTitle']))>0:\n",
    "        print(\"E1\")\n",
    "        KK2=0\n",
    "        \n",
    "    if len(re.findall(r'/',asset_data['AssetTitle']))>0:\n",
    "        print(\"E1\")\n",
    "        KK2=0\n",
    "    if len(re.findall(r'auction',Nline_raw_text))>2:\n",
    "        KK2=0\n",
    "        print(\"E2\")\n",
    "\n",
    "    if len(re.findall(r'Fair Market Value',Nline_raw_text))>2:\n",
    "        KK2=0\n",
    "        print(\"E3\")\n",
    "\n",
    "    return KK2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "def get_assetSpecs(raw_text, asset_specs):    \n",
    "    try:\n",
    "        asset_specs['Kms'] = re.search(r'(?:\\•\\s{4,8})(.*)(km|Km|kms|Kms|KMs|KM|kilometers|Kilometers)',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['EnginePower'] = re.search(r'(?:\\•\\s{4,8})(?:.*)(\\d{3}\\s{0,1})(?:(hp|HP|Hp))',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['Miles'] = re.search(r'(?:\\•\\s{4,8})(.*)(miles|Miles|Mile|mile)',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['Hours'] = re.search(r'(?:\\•\\s{4,8})(?:.*)(.{8})\\s*(?:(hours|Hours|Hrs))',raw_text).group(1).strip()\n",
    "    except:\n",
    "        try:\n",
    "            asset_specs['Hours'] = re.search(r'(?:\\•\\s{4,8})(.*)(?:(hours|Hours|Hrs))',raw_text).group(1).strip()\n",
    "        except:\n",
    "            pass    \n",
    "       \n",
    "    try:\n",
    "        asset_specs['Engine'] = re.search(r'(?:\\•\\s{4,8})(.*engine|Engine)',raw_text).group(1)\n",
    "    except:\n",
    "        try:\n",
    "            asset_specs['Engine'] = re.search(r'(?:\\•\\s{4,8})(.*diesel|Diesel)',raw_text).group(1)\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        asset_specs['Transmission'] = re.search(r'(?:\\•\\s{4,8})(.*)(Transmission|transmission)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['AxlesNo'] = re.search(r'(Tandem|Tridem|(Single axles{0,1})|(Dual axles{0,1}))',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['GVWR'] = re.search(r'(?:\\•\\s{4,8})(.*)(GVWR)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['RearAxle'] = re.search(r'(?:\\•\\s{4,8})(.*)(rear axles{0,1})',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        asset_specs['FrontAxle'] = re.search(r'(?:\\•\\s{4,8})(.*)(front axle)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        asset_specs['Sleeper'] = re.search(r'(?:\\•\\s{4,8})(.*)(Sleeper|sleeper)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['MooseBumper'] = re.search(r'(?:\\•\\s{4,8})(.*)(Moose|Deer)',raw_text).group(1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def get_OtherSpecs(raw_text, other_specs):\n",
    "    Nline_raw_text=re.sub('\\•','\\n•',raw_text)\n",
    "    Nline_raw_text=re.sub('\\n\\n','\\n',Nline_raw_text)\n",
    "\n",
    "    raw_specs = re.findall(r'(?:\\•\\s{4,8})(.{1,})(?:\\n)?',Nline_raw_text)\n",
    "\n",
    "    index = 0\n",
    "    for spec in raw_specs:\n",
    "        #spec=re.sub(r\"\\&\",\" \",spec).strip()\n",
    "        other_specs['Spec'+str(index+1)] = raw_specs[index].strip()\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "def get_assetDscp(raw_text, asset_dscp):\n",
    "    try:\n",
    "        asset_dscp[\"Condition\"] = re.search(r'(good|bad|fair|poor)(?:.{0,10})(?:condition)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        asset_dscp['Type'] = re.search(r'((highway tractor)|truck|RV|unit)',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        asset_dscp['Mechanical'] = re.search(r'((?:Mechanical Description).*(good|bad|fair|poor).*condition',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        asset_dscp['Exterior'] = re.search(r'(?:Exterior).*(good|bad|fair|poor).*condition',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        asset_dscp['Interior'] = re.search(r'(?:Interior).*(good|bad|fair|poor).*condition',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open('MNCCI2018060001.pdf') as pdf:\n",
    "    try:\n",
    "        page = pdf.pages[2]\n",
    "        raw_text = '\\n' + page.extract_text()\n",
    "        try:\n",
    "            Description_data[\"Condition\"] = re.search(r'(good|bad|fair|poor)(?:.{0,10})(?:condition)',raw_text).group(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            Description_data['Type'] = re.search(r'(truck|RV|(highway tractor))',raw_text).group(1).strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            Description_data['Mechanical'] = re.search(r'((?:Mechanical Description).*(good|bad|fair|poor).*condition',raw_text).group(1).strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            Description_data['Exterior'] = re.search(r'(?:Exterior).*(good|bad|fair|poor).*condition',raw_text).group(1).strip()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            Description_data['Interior'] = re.search(r'(?:Interior).*(good|bad|fair|poor).*condition',raw_text).group(1).strip()\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ads': [('Peterbilt 379 L in BC', 'BC', '$50,850.00 '),\n",
       "  ('2002 Peterbilt 379, Good shape. in AB', 'AB', '$34,200.00 ')]}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Ad_data={}\n",
    "with pdfplumber.open('MNCCI2018060001.pdf') as pdf:\n",
    "    try:\n",
    "        page = pdf.pages[5]\n",
    "        raw_text = '\\n' + page.extract_text()\n",
    "        Nline_raw_text = re.sub(\"\\n\",\"\",raw_text)\n",
    "\n",
    "        Ad_data['Ads'] = re.findall(r'(.*in (BC|AB|QC|ON|MN|SK|NB))\\s*(\\$.*)',raw_text)\n",
    "        Ad_data['Auctions'] = re.search(r'(Clsoing)',Nline_raw_text).group(1).strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        print(\"Not\")\n",
    "        pass\n",
    "raw_text\n",
    "Ad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Market Research  Our office has searched similar Peterbilt 379 highway tractors online and in trade publications. To date we have found the following similar items available within the used market.  The description of the item included in each of the following advertisements is presented as originally published by the seller.  Due to the temporary nature of advertisement publication, a copy of each of these documents has been retained for review upon request.  Peterbilt 379 L in BC  $50,850.00 https://www.kijiji.ca/v-heavy-trucks/kamloops/peterbilt-379-l/1357795367?enableSearchNavigationFlag=true  Year2000 Kilometers950,000 Description 6nz cat with 700000 km on platinum in frame 3.73 rear ends, 40000 lbs with locker 15 month old 18 speed and clutch. Complete new front end drum to drum. 24.5 low pro tires, 90% steers, 75% drives. Too many new parts and repairs to mention here.   ** Our office suggests that a 10% adjustment for \"Best Offer\" be applied to this $56,500 published list price.  The anticipated discounted selling price of $50,850 is included in our valuation average. 2002 Peterbilt 379, Good shape. in AB  $34,200.00 https://www.kijiji.ca/v-heavy-trucks/grande-prairie/2002-peterbilt-379-good-shape/1356794843?enableSearchNavigationFlag=true  ColourPurple Year2002 Kilometers1,092,000 Description 2002 Peterbilt 379 New Steers Water pump Radiator U-Joints Rear axle drive seal WetKit Rear axles are super 40’s 3:90 ratio Power divider Truck has a 6NZ Cat motor, 63” sleeper, 240” wheel base  **Note: This unit has greater axle specification. Our office suggests that a 10% adjustment for \"Best Offer\" be applied to this $38,000 published list price.  The anticipated discounted selling price of $34,200 is included in our valuation average.  MNCCI2018060001  6 Of 9 '"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nline_raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORCB2018040001.pdf', 'MNCCI2018060001.pdf', 'MNCCI2018070001.pdf', 'MNCCI2018070002.pdf', 'MNCCI2018120002.pdf', 'MNCCI2018120001.pdf', 'MNCCI2018120002 Addendum.pdf', 'MNCCI2018090001.pdf', 'NIIAT2018060001.pdf']\n",
      "Total Files: 9\n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 1---------------START--------------- \n",
      "PDF PAGES:-----8\n",
      "NORCB2018040001.pdf\n",
      "{'AssetTitle': '2017 Keystone Bullet 272 BHS travel trailer', 'SerialNumber': '4YDT27221HX420798', 'FMV_Low': '19,000', 'FMV_High': '', 'OLV_Low': '8,000', 'OLV_High': '11,000'}\n",
      "17293\n",
      "PDF No: 1---------------FINISH--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 2---------------START--------------- \n",
      "PDF PAGES:-----9\n",
      "MNCCI2018060001.pdf\n",
      "{'AssetTitle': '2000 Peterbilt 379 highway tractor', 'SerialNumber': '1XP5DB9XXYN530611', 'FMV_Low': '30,000', 'FMV_High': '35,000', 'OLV_Low': '20,000', 'OLV_High': '25,000'}\n",
      "17406\n",
      "PDF No: 2---------------FINISH--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 3---------------START--------------- \n",
      "PDF PAGES:-----11\n",
      "MNCCI2018070001.pdf\n",
      "{'AssetTitle': '2013 Western Star 4900SA 40 ton wrecker', 'SerialNumber': '5KKHALDR6DPFF5619', 'FMV_Low': '290,000', 'FMV_High': '300,000', 'OLV_Low': '230,000', 'OLV_High': '240,000'}\n",
      "19018\n",
      "PDF No: 3---------------FINISH--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 4---------------START--------------- \n",
      "PDF PAGES:-----10\n",
      "MNCCI2018070002.pdf\n",
      "{'AssetTitle': '2007 Komo Solution VR520TG CNC router machine', 'SerialNumber': '63070-07 VR520TG', 'FMV_Low': '80,000', 'FMV_High': '90,000', 'OLV_Low': '70,000', 'OLV_High': '75,000'}\n",
      "18128\n",
      "PDF No: 4---------------FINISH--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 5---------------START--------------- \n",
      "PDF PAGES:-----8\n",
      "MNCCI2018120002.pdf\n",
      "{'AssetTitle': '2013 Freightliner Cascadia highway tractor', 'SerialNumber': '1FUJGLDV8DLBT9462', 'FMV_Low': '32,000', 'FMV_High': '35,000', 'OLV_Low': '23,000', 'OLV_High': '26,000'}\n",
      "17619\n",
      "PDF No: 5---------------FINISH--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 6---------------START--------------- \n",
      "PDF PAGES:-----11\n",
      "E1\n",
      "PDF No: 6---------------XX Not Typical PDF 2+ Assets XX--------------- \n",
      "NNot Typical PDF 2+ Assets: MNCCI2018120001.pdf\n",
      "PDF No: 6---------------FINISH--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 7---------------START--------------- \n",
      "PDF No: 7---------------XX File Name Length Error XX--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 8---------------START--------------- \n",
      "PDF PAGES:-----17\n",
      "MNCCI2018090001.pdf\n",
      "{'AssetTitle': '2006 Kenworth W900L highway tractor', 'SerialNumber': '1XKWDB9X46J987252', 'FMV_Low': '55,000', 'FMV_High': '60,000', 'OLV_Low': '45,000', 'OLV_High': '50,000'}\n",
      "22744\n",
      "PDF No: 8---------------FINISH--------------- \n",
      "\n",
      "OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \n",
      "PDF No: 9---------------START--------------- \n",
      "PDF PAGES:-----6\n",
      "NIIAT2018060001.pdf\n",
      "{'AssetTitle': '1971 10x60 mobile home', 'SerialNumber': 'Unknown Mobile Ho', 'FMV_Low': '', 'FMV_High': '', 'OLV_Low': '', 'OLV_High': ''}\n",
      "17997\n",
      "PDF No: 9---------------FINISH--------------- \n",
      "\n",
      "\n",
      "\n",
      "pdfs_not_worked_NameLength:  ['MNCCI2018120002 Addendum.pdf']\n",
      "pdf_not_typical_version:  []\n",
      "Not Typical PDF 2+ Assets:  ['MNCCI2018120001.pdf']\n"
     ]
    }
   ],
   "source": [
    "#Main Script\n",
    "\n",
    "argv = readfiles()\n",
    "\n",
    "print(\"Total Files: \"+ str(len(argv)))\n",
    "\n",
    "#JsonKeys={**Header_Data,**Asset_Data,**Asset_Specs,**Asset_Dscp,**Market_Rsrch,**Other_specs}\n",
    "\n",
    "\n",
    "workfile = \"\"\n",
    "\n",
    "header_data={}\n",
    "asset_data={}\n",
    "asset_specs={}\n",
    "json_data = {}\n",
    "market_research={}\n",
    "other_specs={}\n",
    "asset_dscp={}\n",
    "\n",
    "header_data.update(Header_Data0)\n",
    "asset_data.update(Asset_Data0)\n",
    "asset_specs.update(Asset_Specs0)\n",
    "json_data = JsonKeys\n",
    "market_research.update(Market_Rsrch0)\n",
    "other_specs.update(Other_Specs0)\n",
    "asset_dscp.update(Asset_Dscp0)\n",
    "\n",
    "curr_time = time.strftime(\"%H:%M:%S-%Y,%m,%d\")\n",
    "#json_data = {**header_data, **asset_data, **asset_specs}\n",
    "# Run for each pdf given as an argument\n",
    "iterator=0\n",
    "iter2=0\n",
    "pdf_name_length_Error=[]\n",
    "pdf_not_typical_version=[]\n",
    "pdf_not_typical_2PlusAssets=[]\n",
    "\n",
    "for file in argv:\n",
    "    header_data.update(Header_Data0)\n",
    "    asset_data.update(Asset_Data0)\n",
    "    asset_specs.update(Asset_Specs0)\n",
    "    json_data = JsonKeys\n",
    "    market_research.update(Market_Rsrch0)\n",
    "    other_specs.update(Other_Specs0)\n",
    "    asset_dscp.update(Asset_Dscp0)\n",
    "    Whole_pdf_raw=\"\"\n",
    "    iterator+= 1\n",
    "    print(\"\\n\"+\"OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \")\n",
    "    print(\"PDF No: \"+str(iterator)+\"---------------START--------------- \") \n",
    "    if len(file)==19:\n",
    "        try:\n",
    "            with pdfplumber.open(file) as pdf:\n",
    "                index = 0\n",
    "                raw_text = ''\n",
    "                # Extract all raw text\n",
    "                print(\"PDF PAGES:-----\"+str(len(pdf.pages)))\n",
    "                RunPdf=1\n",
    "                while(index < len(pdf.pages)):\n",
    "                    if RunPdf!=1:\n",
    "                        index=10000\n",
    "                    else:\n",
    "                        page = pdf.pages[index]\n",
    "                        raw_text = '\\n' + page.extract_text()\n",
    "                        Whole_pdf_raw=Whole_pdf_raw+raw_text\n",
    "                        if index ==0 :\n",
    "                            KK1=get_headerData(raw_text, header_data)\n",
    "                            KK2=get_assetData(raw_text, asset_data)\n",
    "                        if KK1==0:\n",
    "                            pdf_not_typical_version.append(file)\n",
    "                            print(\"PDF No: \"+str(iterator)+\"---------------XX Not Typical PDF Version XX--------------- \")\n",
    "                            print(\"Not Typical PDF: \"+file)\n",
    "                            RunPdf=0\n",
    "                        if KK2==0:\n",
    "                            pdf_not_typical_2PlusAssets.append(file)\n",
    "                            print(\"PDF No: \"+str(iterator)+\"---------------XX Not Typical PDF 2+ Assets XX--------------- \")\n",
    "                            print(\"NNot Typical PDF 2+ Assets: \"+file)\n",
    "                            RunPdf=0\n",
    "                        if KK1==0 or KK2==0:\n",
    "                            continue\n",
    "                        \n",
    "                            \n",
    "                        if index==1 and RunPdf!=0:  \n",
    "                            \n",
    "                            get_OtherSpecs(raw_text, other_specs)\n",
    "                            get_assetSpecs(raw_text, asset_specs)\n",
    "\n",
    "                        if index==2 and RunPdf!=0:\n",
    "                            \n",
    "                            get_assetDscp(raw_text, asset_dscp)\n",
    "                            #get_Market_Rsrch(raw_text, asset_specs)\n",
    "                            #get_OtherSpecs(raw_text, asset_specs)\n",
    "\n",
    "                            \n",
    "                        index +=1\n",
    "                if RunPdf!=0:\n",
    "                    print(file)\n",
    "                    print(asset_data)\n",
    "                    iter2+=1\n",
    "                    json_data = {**header_data, **asset_data, **asset_specs,**asset_dscp, **other_specs}\n",
    "                    #print(json_data)       \n",
    "                    df = pandas.DataFrame(json_data, index=[iter2])\n",
    "                    if iterator==1:\n",
    "                        df.to_csv('test {}.csv'.format(curr_time), mode='a', header=True)\n",
    "                    else :\n",
    "                        df.to_csv('test {}.csv'.format(curr_time), mode='a', header=False)\n",
    "                    header_data.update(Header_Data0)\n",
    "                    asset_data.update(Asset_Data0)\n",
    "                    asset_specs.update(Asset_Specs0)\n",
    "                    json_data = JsonKeys\n",
    "                    market_research.update(Market_Rsrch0)\n",
    "                    other_specs.update(Other_Specs0)\n",
    "                    asset_dscp.update(Asset_Dscp0)\n",
    "                    print(str(len(Whole_pdf_raw)))\n",
    "           \n",
    "            print(\"PDF No: \"+str(iterator)+\"---------------FINISH--------------- \")               \n",
    "        except OSError:\n",
    "            print(\"For Loop ERROR:\"+file)\n",
    "            \n",
    "    else:\n",
    "        pdf_name_length_Error.append(file)\n",
    "        print(\"PDF No: \"+str(iterator)+\"---------------XX File Name Length Error XX--------------- \") \n",
    "    \n",
    "     \n",
    "#log.close()\n",
    "print(\"\\n\\n\")\n",
    "print(\"pdfs_not_worked_NameLength: \",pdf_name_length_Error)\n",
    "print(\"pdf_not_typical_version: \",pdf_not_typical_version)\n",
    "print(\"Not Typical PDF 2+ Assets: \",pdf_not_typical_2PlusAssets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['NORCB2018040001.pdf', 'MNCCI2018060001.pdf', 'MNCCI2018070001.pdf', 'MNCCI2018070002.pdf', 'MNCCI2018120002.pdf', 'MNCCI2018120001.pdf', 'MNCCI2018120002 Addendum.pdf', 'MNCCI2018090001.pdf', 'NIIAT2018060001.pdf']\n",
      "PDF No:---------------START--------------- 1\n",
      "PDF PAGES:-----8\n",
      "PDF No:---------------FINISH--------------- 1\n",
      "PDF No:---------------START--------------- 2\n",
      "PDF PAGES:-----9\n",
      "PDF No:---------------FINISH--------------- 2\n",
      "PDF No:---------------START--------------- 3\n",
      "PDF PAGES:-----11\n",
      "PDF No:---------------FINISH--------------- 3\n",
      "PDF No:---------------START--------------- 4\n",
      "PDF PAGES:-----10\n",
      "PDF No:---------------FINISH--------------- 4\n",
      "PDF No:---------------START--------------- 5\n",
      "PDF PAGES:-----8\n",
      "PDF No:---------------FINISH--------------- 5\n",
      "PDF No:---------------START--------------- 6\n",
      "PDF PAGES:-----11\n",
      "PDF No:---------------FINISH--------------- 6\n",
      "PDF No:---------------START--------------- 7\n",
      "PDF PAGES:-----3\n",
      "PDF No:---------------FINISH--------------- 7\n",
      "PDF No:---------------START--------------- 8\n",
      "PDF PAGES:-----17\n",
      "PDF No:---------------FINISH--------------- 8\n",
      "PDF No:---------------START--------------- 9\n",
      "PDF PAGES:-----6\n",
      "PDF No:---------------FINISH--------------- 9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Main Function\n",
    "workfile = \"\"\n",
    "# Setup CSV\n",
    "#curr_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#log = open(str(curr_time) + \".log\",\"w\")\n",
    "\n",
    "def main():\n",
    "    # Check if we are running on all pdfs\n",
    "    print(\"1\")\n",
    "    argv = readfiles()\n",
    "    asset_data = {}\n",
    "    asset_specs = {}\n",
    "    json_data = {}\n",
    "    # Run for each pdf given as an argument\n",
    "    iterator=0\n",
    "    for file in argv:\n",
    "        iterator= iterator+1\n",
    "        print(\"PDF No:---------------START--------------- \"+str(iterator)) \n",
    "        try:\n",
    "            header_data = {}\n",
    "            with pdfplumber.open(file) as pdf:\n",
    "                index = 0\n",
    "                raw_text = ''\n",
    "                # Extract all raw text\n",
    "                print(\"PDF PAGES:-----\"+str(len(pdf.pages)))\n",
    "                while(index < len(pdf.pages)):\n",
    "                    page = pdf.pages[index]\n",
    "                    raw_text = '\\n' + page.extract_text()\n",
    "                    if index ==0 :\n",
    "                        get_headerData(raw_text, header_data)\n",
    "\n",
    "                    index += 1\n",
    "            print(\"PDF No:---------------FINISH--------------- \"+str(iterator))            \n",
    "        except OSError:\n",
    "            print(\"ERROR\")\n",
    "    #log.close()\n",
    "    print(\"1\")\n",
    "\n",
    "if (__name__ == '__main__'):\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ADECG2010120001.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/hc79rm6j1qx6dm1xrbn04f900000gn/T/ipykernel_8749/2841566115.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDescription_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ADECG2010120001.pdf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mstream_is_external\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ADECG2010120001.pdf'"
     ]
    }
   ],
   "source": [
    "Description_data={}\n",
    "with pdfplumber.open('ADECG2010120001.pdf') as pdf:\n",
    "    try:\n",
    "        page = pdf.pages[2]\n",
    "        raw_text = '\\n' + page.extract_text()\n",
    "        raw_text=re.sub(\"\\n\",\" \",raw_text)\n",
    "        Description_data['Type'] = re.search(r'(truck|RV)',raw_text).group(1).strip()\n",
    "        #Description_data['Exterior'] = re.search(r'(Exterior',raw_text).group(1).strip()\n",
    "        #Description_data['Interior'] = re.search(r'(Interior',raw_text).group(1).strip()\n",
    "\n",
    "        Description_data['Mechanical'] = re.search(r'(Mechanical Description).*(good|bad|fair|poor).*condition',raw_text).group(2).strip()\n",
    "    except AttributeError:\n",
    "        print(\"Not\")\n",
    "        pass\n",
    "raw_text\n",
    "Description_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs debugging Description and Ads\n",
    "Description_data={}\n",
    "with pdfplumber.open('ADECG2010120001.pdf') as pdf:\n",
    "    try:\n",
    "        page = pdf.pages[2]\n",
    "        raw_text = '\\n' + page.extract_text()\n",
    "        raw_text\n",
    "        Description_data['Type'] = re.search(r'(truck|RV)',raw_text).group(1).strip()\n",
    "        Description_data['Exterior'] = re.search(r'(Exterior',raw_text).group(1).strip()\n",
    "        Description_data['Interior'] = re.search(r'(Interior',raw_text).group(1).strip()\n",
    "\n",
    "        Description_data['Mechanical'] = re.search(r'(Mechanical Description ',raw_text).group(1).strip()\n",
    "    except AttributeError:\n",
    "        print(\"Not\")\n",
    "        pass\n",
    "raw_text\n",
    "Description_data\n",
    "\n",
    "\n",
    "\n",
    "Ad_data={}\n",
    "with pdfplumber.open('ADECG2010120001.pdf') as pdf:\n",
    "    try:\n",
    "        page = pdf.pages[5]\n",
    "        raw_text = '\\n' + page.extract_text()\n",
    "        raw_text\n",
    "\n",
    "        Description_data['Ads'] = re.search(r'(Market Research',raw_text).group(1).strip()\n",
    "        Description_data['Auctions'] = re.search(r'(Clsoing',raw_text).group(1).strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        print(\"Not\")\n",
    "        pass\n",
    "raw_text\n",
    "ad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_data.update(Asset_Data0)\n",
    "with pdfplumber.open('ADESK2020110002.pdf') as pdf:   \n",
    "    page = pdf.pages[0]\n",
    "    raw_text = '\\n' + page.extract_text()\n",
    "    Nline_raw_text=re.sub(\"\\n\",\" \",raw_text)\n",
    "    Nline_raw_text=re.sub(\"  \",\" \",Nline_raw_text)\n",
    "    Nline_raw_text=re.sub(\"  \",\" \",Nline_raw_text)\n",
    "    Nline_raw_text=re.sub(\"  \",\" \",Nline_raw_text)\n",
    "    \n",
    "    try:\n",
    "        asset_data['AssetTitle'] = re.search(r'described (.{1,}) based on',Nline_raw_text).group(1).strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            asset_data['AssetTitle'] = re.search(r'(Item\\s{1,}:\\s{1,})(\\d{4}?.{1,})(Serial Number)',Nline_raw_text).group(2).strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "        asset_data['SerialNumber'] = re.search(r'(Serial Number\\s{1,}:\\s{1,})(.{1,}?)(\\s{1})',Nline_raw_text).group(2).strip()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    try:# FMV/ACV FMV high low/single\n",
    "        asset_data['FMV_Low'] = re.search(r'((Fair Market Value|(Actual Cash Value)) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))',Nline_raw_text).group(5).strip()\n",
    "        asset_data['FMV_High'] = re.search(r'((Fair Market Value|(Actual Cash Value)) (of|in the)\\s{1,}\\$)((\\d{1,}\\,)?(\\d{1,}))(\\s*-\\s*\\$*)(\\d{1,}\\,\\d{1,})',Nline_raw_text).group(9).strip()\n",
    "    except AttributeError:\n",
    "        print(\"x\")\n",
    "        pass\n",
    "    \n",
    "    try:# OLV/Auction value low/single\n",
    "        print(re.search(r'(auction\\s*\\w* (of|in the)\\s{1,}\\$)(\\d{1,}(\\,\\d{2,})?)((\\s*.{1}\\s*\\$*)(\\d{1,}(\\,\\d{2,})?))',Nline_raw_text))\n",
    "\n",
    "        asset_data['OLV_Low'] = re.search(r'(auction\\s*\\w* (of|in the)\\s{1,}\\$)(\\d{1,}(\\,\\d{2,})?)((\\s*.{1}\\s*\\$*)(\\d{1,}(\\,\\d{2,})?))',Nline_raw_text).group(3).strip()\n",
    "        asset_data['OLV_High'] = re.search(r'(auction\\s*\\w* (of|in the)\\s{1,}\\$)(\\d{1,}(\\,\\d{2,})?)((\\s*.{1}\\s*\\$*)(\\d{1,}(\\,\\d{2,})?))',Nline_raw_text).group(7).strip()\n",
    "    except AttributeError:\n",
    "        print(\"X\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_specs.update(Other_Specs0)\n",
    "raw_specs=[]\n",
    "with pdfplumber.open('ADECG2010120001.pdf') as pdf:   \n",
    "    page = pdf.pages[1]\n",
    "    raw_text = '\\n' + page.extract_text()\n",
    "    \n",
    "    Nline_raw_text=re.sub('\\•','\\n•',raw_text)\n",
    "    Nline_raw_text=re.sub('\\n\\n','\\n',Nline_raw_text)\n",
    "\n",
    "    raw_specs = re.findall(r'(?:\\•\\s{4,8})(.{1,})(?:\\n)?',Nline_raw_text)\n",
    "\n",
    "    index = 0\n",
    "    for spec in raw_specs:\n",
    "        #spec=re.sub(r\"\\&\",\" \",spec).strip()\n",
    "        other_specs['Spec'+str(index+1)] = raw_specs[index].strip()\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spec1': 'Cat C15 475hp engine',\n",
       " 'Spec2': 'Eaton 18 speed transmission',\n",
       " 'Spec3': '63\" raised sleeper',\n",
       " 'Spec4': '12,000lb front axle',\n",
       " 'Spec5': '40,000lb rear axles',\n",
       " 'Spec6': 'Air ride suspension',\n",
       " 'Spec7': 'Aluminum wheels',\n",
       " 'Spec8': 'Power windows and locks',\n",
       " 'Spec9': 'Air conditioning',\n",
       " 'Spec10': 'CD/stereo',\n",
       " 'Spec11': 'Dual exhaust',\n",
       " 'Spec12': 'Mud flaps',\n",
       " 'Spec13': 'Stainless fenders',\n",
       " 'Spec14': 'Beacon lamps',\n",
       " 'Spec15': 'Marker lamp kit',\n",
       " 'Spec16': 'Fridge',\n",
       " 'Spec17': '887,085 KMs',\n",
       " 'Spec18': '',\n",
       " 'Spec19': '',\n",
       " 'Spec20': '',\n",
       " 'Spec21': '',\n",
       " 'Spec22': '',\n",
       " 'Spec23': '',\n",
       " 'Spec24': '',\n",
       " 'Spec25': '',\n",
       " 'Spec26': '',\n",
       " 'Spec27': '',\n",
       " 'Spec28': '',\n",
       " 'Spec29': '',\n",
       " 'Spec30': '',\n",
       " 'Spec31': '',\n",
       " 'Spec32': '',\n",
       " 'Spec33': '',\n",
       " 'Spec34': '',\n",
       " 'Spec35': '',\n",
       " 'Spec36': '',\n",
       " 'Spec37': '',\n",
       " 'Spec38': '',\n",
       " 'Spec39': ''}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "Asset_Specs0={\"Kms\":\"\",\"Hours\":\"\",\"Miles\":\"\",\"Engine\":\"\",\"EnginePower\":\"\",\"Transmission\":\"\",\"AxlesNo\":\"\",\"GVWR\":\"\",\"RearAxle\":\"\",\n",
    "              \"FrontAxle\":\"\",\"Sleeper\":\"\",\"MooseBumper\":\"\"}\n",
    "asset_specs.update(Asset_Specs0)\n",
    "with pdfplumber.open(\"MNCCI2018060001.pdf\") as pdf:\n",
    "    page = pdf.pages[1]\n",
    "    raw_text = '\\n' + page.extract_text()\n",
    "\n",
    " \n",
    "    try:\n",
    "        asset_specs['Kms'] = re.search(r'(?:\\•\\s{4,8})(.*)(km|Km|kms|Kms|KMs|KM|kilometers|Kilometers)',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['EnginePower'] = re.search(r'(?:\\•\\s{4,8})(?:.*)(\\d{3}\\s{0,1})(?:(hp|HP|Hp))',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['Miles'] = re.search(r'(?:\\•\\s{4,8})(.*)(miles|Miles|Mile|mile)',raw_text).group(1).strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['Hours'] = re.search(r'(?:\\•\\s{4,8})(.*)\\s*(?:(hours|Hours|Hrs))',raw_text).group(1).strip()\n",
    "    except:\n",
    "        try:\n",
    "            asset_specs['Hours'] = re.search(r'(?:\\•\\s{4,8})(.*)(?:(hours|Hours|Hrs))',raw_text).group(1).strip()\n",
    "        except:\n",
    "            pass    \n",
    "       \n",
    "    try:\n",
    "        asset_specs['Engine'] = re.search(r'(?:\\•\\s{4,8})(.*engine|Engine)',raw_text).group(1)\n",
    "    except:\n",
    "        try:\n",
    "            asset_specs['Engine'] = re.search(r'(?:\\•\\s{4,8})(.*diesel|Diesel)',raw_text).group(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        asset_specs['Transmission'] = re.search(r'(?:\\•\\s{4,8})(.*)(Transmission|transmission)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['AxlesNo'] = re.search(r'(Tandem|Tridem|(Single axles{0,1})|(Dual axles{0,1}))',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['GVWR'] = re.search(r'(?:\\•\\s{4,8})(.*)(GVWR)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['RearAxle'] = re.search(r'(?:\\•\\s{4,8})(.*)(rear axles{0,1})',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        asset_specs['FrontAxle'] = re.search(r'(?:\\•\\s{4,8})(.*)(front axle)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        asset_specs['Sleeper'] = re.search(r'(?:\\•\\s{4,8})(.*)(Sleeper|sleeper)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        asset_specs['MooseBumper'] = re.search(r'(?:\\•\\s{4,8})(.*)(Moose|Deer)',raw_text).group(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spec1': '760,361 kilometers indicated (assumed rolled over)',\n",
       " 'Spec2': 'Caterpillar C15 diesel engine (490hp)',\n",
       " 'Spec3': '18 speed manual transmission',\n",
       " 'Spec4': 'Tandem axle',\n",
       " 'Spec5': '50,000 lbs GVWR',\n",
       " 'Spec6': '12,000 lbs front axle',\n",
       " 'Spec7': '38,000 lbs rear axles',\n",
       " 'Spec8': '62\" raised roof sleeper',\n",
       " 'Spec9': 'Aerodynamic air deflector',\n",
       " 'Spec10': 'Alloy wheels',\n",
       " 'Spec11': 'Sliding fifth wheel hitch',\n",
       " 'Spec12': 'Air ride suspension',\n",
       " 'Spec13': 'External air cleaners',\n",
       " 'Spec14': 'Dual chrome exhausts',\n",
       " 'Spec15': 'Sun visor',\n",
       " 'Spec16': 'Rear LED work lights',\n",
       " 'Spec17': 'Cloth seats/ Full load',\n",
       " 'Spec18': 'Remote lube system',\n",
       " 'Spec19': '',\n",
       " 'Spec20': '',\n",
       " 'Spec21': '',\n",
       " 'Spec22': '',\n",
       " 'Spec23': '',\n",
       " 'Spec24': '',\n",
       " 'Spec25': '',\n",
       " 'Spec26': '',\n",
       " 'Spec27': '',\n",
       " 'Spec28': '',\n",
       " 'Spec29': '',\n",
       " 'Spec30': '',\n",
       " 'Spec31': '',\n",
       " 'Spec32': '',\n",
       " 'Spec33': '',\n",
       " 'Spec34': '',\n",
       " 'Spec35': '',\n",
       " 'Spec36': '',\n",
       " 'Spec37': '',\n",
       " 'Spec38': '',\n",
       " 'Spec39': ''}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_specs.update(Other_Specs0)\n",
    "raw_specs=[]\n",
    "with pdfplumber.open('MNCCI2018060001.pdf') as pdf:   \n",
    "    page = pdf.pages[1]\n",
    "    raw_text = '\\n' + page.extract_text()\n",
    "    \n",
    "    Nline_raw_text=re.sub('\\•','\\n•',raw_text)\n",
    "    Nline_raw_text=re.sub('\\n\\n','\\n',Nline_raw_text)\n",
    "\n",
    "    raw_specs = re.findall(r'(?:\\•\\s{4,8})(.{1,})(?:\\n)?',Nline_raw_text)\n",
    "\n",
    "    index = 0\n",
    "    for spec in raw_specs:\n",
    "        #spec=re.sub(r\"\\&\",\" \",spec).strip()\n",
    "        other_specs['Spec'+str(index+1)] = raw_specs[index].strip()\n",
    "        index += 1\n",
    "other_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
